#!/usr/bin/env python

import sys
import os
import time
import argparse
import traceback

import avro.schema

from kafka_connect_session import KafkaConnectSession
from cassandra_session import CassandraSession

from print_utils import pretty_print
from connector import Connector
from sonar_directory_source_config import SonarDirectorySourceConfig, FileFormat
from cassandra_sink_config import CassandraSinkConfig


def create_connectors(args, avro_schema):
    """ Create directory source and Cassandra sink connector objects """

    # Get absolute paths
    current_dir = os.getcwd()
    ingest_dir = args.ingest_dir 
    completed_dir = args.completed_dir 
    ingest_dir_fullpath = os.path.join(current_dir, ingest_dir)
    completed_dir_fullpath = os.path.join(current_dir, completed_dir)

    # Create unique topic
    topic_name = str(int(time.time())) + "-" + str(hash(ingest_dir_fullpath)) + "--" + args.keyspace + "." + args.table

    # Create Connector objects
    directory_source = Connector(
        "sonar-directory-source-" + topic_name,
        SonarDirectorySourceConfig(
            topic_name,
            ingest_dir_fullpath,
            completed_dir_fullpath,
            avro_schema,
            tasks_max=args.tasks_max,
            file_format=FileFormat(args.file_format),
            format_options=args.format_options,
            batch_size=args.batch_size
        )
    )
    cassandra_sink = Connector(
        "cassandra-sink-" + topic_name,
        CassandraSinkConfig(
            topic_name,
            args.keyspace,
            args.table,
            args.cassandra_username,
            args.cassandra_password_file,
            cassandra_host=args.cassandra_host,
            cassandra_port=args.cassandra_port,
            tasks_max=args.tasks_max
        )
    )

    if args.debug:
        pretty_print("Sonar directory connector", directory_source.json())
        pretty_print("Cassandra sink connector", cassandra_sink.json())

    return [directory_source, cassandra_sink]


def parse_args():
    """ Parse arguments """

    parser = argparse.ArgumentParser(
            description="creates a Kafka ingestion file source for a Cassandra table, "
                        "creating the table if it does not yet exist.",
            formatter_class=argparse.RawTextHelpFormatter)

    parser.add_argument('-d', '--dry', action="store_true", required=False,
            help="dry run")
    parser.add_argument('-g', '--debug', action="store_true", required=False,
            help="debug this script")
    parser.add_argument('-f', '--file-format', default="json", required=False,
            help="file format (json|csv)")
    parser.add_argument('-fo', '--format-options', default="{}", required=False,
            help="file format options")
    parser.add_argument('-t', '--tasks-max', default="1", required=False,
            help="maximum number of concurrent ingestion tasks")
    parser.add_argument('-b', '--batch-size', default="10000", required=False,
            help="batch size for file reads")
    parser.add_argument('-i', '--ingest-dir', required=True,
            help="directory to use as ingestion point")
    parser.add_argument('-o', '--completed-dir', required=True,
            help="directory to move ingested files into")
    parser.add_argument('-k', '--kafka-rest-url', default="localhost", required=False,
            help="URL of kafka rest endpoint (default localhost)")
    parser.add_argument('-kp', '--kafka-rest-port', default="8083", required=False,
            help="Port of kafka rest endpoint (default 8083)")
    parser.add_argument('-c', '--cassandra-host', default="localhost", required=False,
            help="Cassandra host to connect to (default localhost)")
    parser.add_argument('-cp', '--cassandra-port', default="9042", required=False,
            help="Cassandra port to connect to (default 9042)")
    parser.add_argument('-u', '--cassandra-username', required=True,
            help="Cassandra username to ingest with (REQUIRED)")
    parser.add_argument('-p', '--cassandra-password-file', required=True,
            help="Cassandra password file to authenticate with (REQUIRED)")
    parser.add_argument('-pk', '--partition-key', type=str, required=False,
            help="one or more partition keys, comma-separated, no spaces."
                 "\nNOTE: this argument is required if Cassandra table is not yet created"
                 "\nexamples:"
                 "\n    partition_key"
                 "\n    partition_key1,partition_key2")
    parser.add_argument('-ck', '--cluster-key', type=str, required=False,
            help="one or more cluster keys, comma-separated, no spaces"
                 "\nexamples:"
                 "\n   cluster_key"
                 "\n   cluster_key1,cluster_key2")

    parser.add_argument('avro_schema_file', help="Avro schema file")
    parser.add_argument('keyspace', type=str, help="Cassandra keyspace to ingest into")
    parser.add_argument('table', type=str, help="Cassandra table to ingest into")

    args = parser.parse_args()

    if args.debug:
        pretty_print("Arguments passed", args.__dict__)

    return args


def main():
    """ Main entrypoint """

    args = parse_args()

    try:

        # Get avro schema from file
        with open(args.avro_schema_file, 'r') as f:
            avro_schema = avro.schema.Parse(f.read())
        if args.debug:
            pretty_print("Avro schema", avro_schema.to_json())

        # Initialize Kafka Connect REST session
        kafka_connect_session = KafkaConnectSession(
            args.dry, 
            args.debug, 
            args.kafka_rest_url,
            args.kafka_rest_port
        )

        # Check for directory source and cassandra sink connector plugins
        if not args.dry:
            plugins = kafka_connect_session.request('GET', '/connector-plugins').json()
            plugin_classes = [plugin['class'] for plugin in plugins]
            for required_class in [SonarDirectorySourceConfig.CONNECTOR_CLASS]:
                if required_class not in plugin_classes:
                    raise Exception("Connector class not available: '{}'".format(required_class))

        # Check if Cassandra table exists, and if not, try to make it
        cassandra_session = CassandraSession(
            args.cassandra_username, 
            args.cassandra_password_file, 
            hosts=[args.cassandra_host], 
            port=args.cassandra_port, 
            dry=args.dry, 
            debug=args.debug
        )
        if not cassandra_session.table_exists(args.keyspace, args.table):
            if args.partition_key is not None:
                cassandra_session.create_table_from_avro_schema(
                    args.keyspace,
                    args.table,
                    avro_schema,
                    args.partition_key,
                    args.cluster_key
                )
            else:
                raise Exception("Table {}.{} does not exist, and no partition key was defined to create it!".format(args.keyspace, args.table))

        # Create the connector objects
        connectors = create_connectors(args, avro_schema)

        # Create the connectors!
        for connector in connectors:
            kafka_connect_session.create_connector(connector)

    except Exception as e:
        exc_type, exc_value, exc_traceback = sys.exc_info()
        traceback.print_exception(exc_type, exc_value, exc_traceback, limit=2, file=sys.stderr)
        return 1


if __name__ == '__main__':
    main()
