{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Spark and Sonar Cassandra Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonar_driver.spark import analytics as analytics\n",
    "\n",
    "import os\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-1.8.0/'\n",
    "os.environ['SPARK_HOME'] = '/g/g13/wang109/spark-2.3.1-bin-hadoop2.7'\n",
    "os.environ['JAVA_OPTS'] = '-Djavax.net.ssl.trustStore=/etc/pki/ca-trust/extracted/java/cacerts'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = (\n",
    "    '--master local[*] '\n",
    "    '--packages com.datastax.spark:spark-cassandra-connector_2.11:2.3.0 '\n",
    "    'pyspark-shell'\n",
    ")\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, TimestampType\n",
    "from pyspark.sql.functions import col, lit, split, udf, explode\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from sonar_auth.cassandra import SonarCassandraSession\n",
    "session = SonarCassandraSession(['rzsonar8'])\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName('cassandra')\n",
    "        .config('spark.cassandra.connection.host', session.hosts_string)\n",
    "        .config('spark.cassandra.auth.username', session.username)\n",
    "        .config('spark.cassandra.auth.password', session.token)\n",
    "        .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read job data from Cassandra and store in Spark dataframe with appropriate column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkdf = (\n",
    "    spark.read.format('org.apache.spark.sql.cassandra')\n",
    "        .options(keyspace='lcstaff_k', table='jobdata')\n",
    "        .load()\n",
    "        .select(['JobId', 'Cluster', 'StartTime', 'scontrol'])\n",
    "        .withColumn('JobId', col('JobId').cast(IntegerType()))\n",
    "        .withColumn('StartTime', col('StartTime').cast(TimestampType()))\n",
    "        .withColumn('EndTime', col('scontrol')['EndTime'].cast(TimestampType()))\n",
    "        .drop('scontrol')\n",
    ")\n",
    "\n",
    "sparkdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query jobs within a time range and on certain clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = ['2018-05-16T07:27:21', '2018-05-17T07:27:21', 'EndTime']\n",
    "clusters = ['rzgenie', 'rztopaz']\n",
    "\n",
    "queried_sparkdf = analytics.query(sparkdf, time_range=time_range, clusters=clusters)\n",
    "queried_sparkdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate discrete derivatives based on window size and slide length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics.discrete_derivatives(queried_sparkdf, 'EndTime', window_size=300, slide_length=300).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate discrete integrals based on slide length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics.discrete_integrals(queried_sparkdf, slide_length=10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original dataframe is unaltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SIA",
   "language": "python",
   "name": "sia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
